{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79d6890-0442-4662-bf4d-69578941542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSA_OVERRIDE_GFX_VERSION is set to: 11.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '11.0.0'\n",
    "\n",
    "gfx_version = os.getenv('HSA_OVERRIDE_GFX_VERSION')\n",
    "print(f\"HSA_OVERRIDE_GFX_VERSION is set to: {gfx_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2b0615-33b1-4460-bd52-4e7449fb4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1989825-7153-4426-8389-1b7c9b9af9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '11.0.0'\n",
    "\n",
    "t = torch.tensor([5, 5, 5], dtype=torch.int64, device='cuda')\n",
    "t_f32 = torch.tensor([5, 5, 5], dtype=torch.float32, device='cuda')\n",
    "print('Testing PyTorch ROCM support...')\n",
    "\n",
    "print(t, t_f32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc61a0e8-ff43-4998-8e30-f6d7e726618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf  --break-system-packages -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71e2541-5cf3-4992-8f22-c21de37eca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import textwrap\n",
    "\n",
    "def load_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a88c52f-53ed-41b2-9d3e-99164423539f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702184"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_textual_data = load_pdf(\"_OceanofPDF.com_Build_a_Large_Language_Model_From_Scratch_-_Sebastian_Raschka-3.pdf\")\n",
    "len(pdf_textual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2566ceb2-a23b-4a26-baa1-f33cfe3f368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90275540-2ec4-4c28-8b50-b1f88d0d2aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"nomic-ai/nomic-embed-text-v1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbb1ed4d-1f7c-4272-8f22-b0cc6f8719f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops --break-system-packages -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce4a73ae-29a6-4cd5-9427-c63f29da2e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "nomic-ai/nomic-bert-2048 You can inspect the repository content at https://hf.co/nomic-ai/nomic-embed-text-v1.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n",
      "The repository nomic-ai/nomic-embed-text-v1 references custom code contained in nomic-ai/nomic-bert-2048 which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/nomic-ai/nomic-bert-2048 .\n",
      " You can inspect the repository content at https://hf.co/nomic-ai/nomic-embed-text-v1.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 13:27:41.394600: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 13:27:41.793243: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/init/.local/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.30.2 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-12-09 13:27:44.032773: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63e8281ef764277a516d113d4236288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/547M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NomicBertModel(\n",
       "  (embeddings): NomicBertEmbeddings(\n",
       "    (word_embeddings): Embedding(30528, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "  (emb_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (encoder): NomicBertEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x NomicBertBlock(\n",
       "        (attn): NomicBertAttention(\n",
       "          (rotary_emb): NomicBertDynamicNTKRotaryEmbedding()\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): NomciBertGatedMLP(\n",
       "          (fc11): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (fc12): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3525ecb0-ca22-46a8-8d51-537ae5443935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text: str):\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "\n",
    "    # embeddings = mean pooling of last hidden state\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    mask = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "    emb = torch.sum(hidden_states * mask, dim=1) / torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5379720c-842c-4853-9f60-5d8a48b37fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_embedding = embed(\"This is my institute\")\n",
    "raw_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06d68f-7daa-4797-b900-5d9e1c108d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89564580-f18e-4ef9-9cad-639fdadce46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eadedd2-968c-466f-bd99-b2f3a18a1046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1510"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "text_chunk = splitter.split_text(pdf_textual_data)\n",
    "len(text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa9c3f-1285-4a33-bfb0-761613aa0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19ad47af-a133-4820-803c-edddd5bc54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"pdf_chunks\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}  # cosine similarity for embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df975803-0765-4aa3-bb99-a178103ca2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def embed_texts(text_list):\n",
    "    vectors = []\n",
    "    for text in text_list:\n",
    "        v = embed(text)            # your embed() function returns tensor [1, dim]\n",
    "        v = v.cpu().numpy()[0]     # convert to numpy\n",
    "        vectors.append(v.tolist()) # convert to Python list\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fe14008-ed56-4f14-8c25-adc9beeab837",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [str(uuid.uuid4()) for _ in range(len(text_chunk))]\n",
    "embeddings = embed_texts(text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90577021-edb9-4027-9ab6-24394287db28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1510, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50fcb866-5656-4c85-8cd0-13df5477eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=text_chunk,\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14a7ed4d-882a-422a-a441-47e0f910c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How the token embeddings are created in the LLM\"\n",
    "q_emb = embed(query).cpu().numpy()[0].tolist()\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[q_emb],\n",
    "    n_results=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0b40087-16ab-4655-b97f-ea95a846534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['111 111 111 111\\n'\n",
      " 'Embedding of the ﬁrst token Embedding of the third token\\n'\n",
      " 'Figure 2.18 Positional embeddings are added to the token embedding vector to '\n",
      " 'create the \\n'\n",
      " 'input embeddings for an LLM. The positional vectors have the same dimension '\n",
      " 'as the original \\n'\n",
      " 'token embeddings. The token embeddings are shown with value 1 for '\n",
      " 'simplicity.\\n'\n",
      " '46 CHAPTER 2 Working with text data\\n'\n",
      " ' Previously, we focused on very small embedding sizes for simplicity. Now, '\n",
      " 'let’s con-',\n",
      " 'IDs to create the token embedding vectors.\\n'\n",
      " '42 CHAPTER 2 Working with text data\\n'\n",
      " 'these embedding weights with random values. This initialization serves as '\n",
      " 'the starting\\n'\n",
      " 'point for the LLM’s learning process. In chapter 5, we will optimize the '\n",
      " 'embedding\\n'\n",
      " 'weights as part of the LLM training.\\n'\n",
      " ' A continuous vector representation, or embedding, is necessary since '\n",
      " 'GPT-like\\n'\n",
      " 'LLMs are deep neural networks trained with the backpropagation algorithm.',\n",
      " 'Having now created embedding vectors from token IDs, next we’ll add a small\\n'\n",
      " 'modification to these embedding vectors to encode positional information '\n",
      " 'about a\\n'\n",
      " 'token within a text.\\n'\n",
      " '2.8 Encoding word positions\\n'\n",
      " 'In principle, token embeddings are a suitable input for an LLM. However, a '\n",
      " 'minor\\n'\n",
      " 'shortcoming of LLMs is that their self-attention mechanism (see chapter 3) '\n",
      " 'doesn’t\\n'\n",
      " 'have a notion of position or order for the tokens within a sequence. The way '\n",
      " 'the pre-',\n",
      " 'often appear close to each other in the embedding space. For instance, '\n",
      " 'different types \\n'\n",
      " 'of birds appear closer to each other in the embedding space than in '\n",
      " 'countries and cities.\\n'\n",
      " '212.2 Tokenizing text\\n'\n",
      " '2.2 Tokenizing text\\n'\n",
      " 'Let’s discuss how we split input text into individual tokens, a required '\n",
      " 'preprocessing\\n'\n",
      " 'step for creating embeddings for an LLM. These tokens are either individual '\n",
      " 'words or\\n'\n",
      " 'special characters, including punctuation characters, as shown in figure '\n",
      " '2.4.',\n",
      " 'You’ll learn how to prepare input text for training LLMs. This involves '\n",
      " 'splitting text\\n'\n",
      " 'into individual word and subword tokens, which can then be encoded into '\n",
      " 'vector rep-\\n'\n",
      " 'resentations for the LLM. You’ll also learn about advanced tokenization '\n",
      " 'schemes like\\n'\n",
      " 'byte pair encoding, which is utilized in popular LLMs like GPT. Lastly, '\n",
      " 'we’ll imple-\\n'\n",
      " 'ment a sampling and data-loading strategy to produce the input-output pairs '\n",
      " 'neces-\\n'\n",
      " 'sary for training LLMs.\\n'\n",
      " '2.1 Understanding word embeddings',\n",
      " '[ 5891,  1576,   438,   568],\\n'\n",
      " '        [  340,   373,   645,  1049],\\n'\n",
      " '        [ 5975,   284,   502,   284],\\n'\n",
      " '        [ 3285,   326,    11,   287]])\\n'\n",
      " 'Note that we increase the stride to 4 to utilize the data set fully (we '\n",
      " 'don’t skip a single\\n'\n",
      " 'word). This avoids any overlap between the batches since more overlap could '\n",
      " 'lead to\\n'\n",
      " 'increased overfitting.\\n'\n",
      " '2.7 Creating token embeddings\\n'\n",
      " 'The last step in preparing the input text for LLM training is to convert the '\n",
      " 'token IDs',\n",
      " 'during the training process rather than being fixed or predefined like the '\n",
      " 'positional\\n'\n",
      " 'encodings in the original transformer model. This optimization process is '\n",
      " 'part of the\\n'\n",
      " 'model training itself. For now, let’s create the initial positional '\n",
      " 'embeddings to create the\\n'\n",
      " 'LLM inputs.\\n'\n",
      " 'Input embeddings:\\n'\n",
      " 'Positional embeddings:\\n'\n",
      " 'Token embeddings:\\n'\n",
      " '++ + +\\n'\n",
      " '2.1 2.2 2.3 3.1 3.2 3.3 4.1 4.2 4.3 5.1 5.2 5.3\\n'\n",
      " '1.1 1.2 1.3 2.1 2.2 2.3 3.1 3.2 3.3 4.1 4.2 4.3\\n'\n",
      " '111 111 111 111',\n",
      " 'example, the token ID 5, whether it’s in the first or fourth position in '\n",
      " 'the \\n'\n",
      " 'token ID input vector, will result in the same embedding vector.\\n'\n",
      " '452.8 Encoding word positions\\n'\n",
      " 'In principle, the deterministic, position-independent embedding of the token '\n",
      " 'ID is\\n'\n",
      " 'good for reproducibility purposes. However, since the self-attention '\n",
      " 'mechanism of\\n'\n",
      " 'LLMs itself is also position-agnostic, it is helpful to inject additional '\n",
      " 'position informa-\\n'\n",
      " 'tion into the LLM.',\n",
      " 'embedding vectors and are optimized during the model training.\\n'\n",
      " '50\\n'\n",
      " 'Coding attention\\n'\n",
      " 'mechanisms\\n'\n",
      " 'At this point, you know how to prepare the input text for training LLMs by '\n",
      " 'splitting\\n'\n",
      " 'text into individual word and subword tokens, which can be encoded into '\n",
      " 'vector rep-\\n'\n",
      " 'resentations, embeddings, for the LLM. \\n'\n",
      " ' Now, we will look at an integral part of the LLM architecture itself, '\n",
      " 'attention\\n'\n",
      " 'mechanisms, as illustrated in figure 3.1. We will largely look at attention '\n",
      " 'mechanisms',\n",
      " 'text into tokens\\n'\n",
      " 'Figure 2.4 A view of the text processing steps in the context of an LLM. '\n",
      " 'Here, we split an \\n'\n",
      " 'input text into individual tokens, which are either words or special '\n",
      " 'characters, such as \\n'\n",
      " 'punctuation characters.\\n'\n",
      " '22 CHAPTER 2 Working with text data\\n'\n",
      " 'import urllib.request\\n'\n",
      " 'url = (\"https://raw.githubusercontent.com/rasbt/\"\\n'\n",
      " '       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\\n'\n",
      " '       \"the-verdict.txt\")\\n'\n",
      " 'file_path = \"the-verdict.txt\"\\n'\n",
      " 'urllib.request.urlretrieve(url, file_path)']\n",
      "[0.21586394309997559,\n",
      " 0.24216091632843018,\n",
      " 0.2578219175338745,\n",
      " 0.2639656066894531,\n",
      " 0.26629817485809326,\n",
      " 0.2695058584213257,\n",
      " 0.28770285844802856,\n",
      " 0.2959333658218384,\n",
      " 0.29833829402923584,\n",
      " 0.30006086826324463]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for para in results[\"documents\"]:\n",
    "    pprint(para)\n",
    "\n",
    "for para in results[\"distances\"]:\n",
    "    pprint(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292632d9-e4e4-481d-8d43-dd44591b7ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "036acf673e8f45c6a264d40658edae8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "05aa7474791d41f58c1dc859b1b4b595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_82c743017aed423dae8778cdd386a35f",
       "style": "IPY_MODEL_3a59711ccbb24883ab5a7f695e1ba062",
       "value": "tokenizer_config.json: "
      }
     },
     "0649795efffb49ff8283a2534c5a1bc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7fa5ec81853f4c4e82ae9bfb4dffb7ed",
       "style": "IPY_MODEL_a7cea972468a4a1bad1fbbb94f6bf7ec",
       "value": " 232k/? [00:00&lt;00:00, 2.48MB/s]"
      }
     },
     "07657f0e591f45b2bd6daea0bf3a709a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d10328fa0d94ad8b5f088811d9eadeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0e9d2d36ac7d4242bce4bb490eaea8a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f4c8f8c5acf545bc95ef6f620d94a5b0",
       "style": "IPY_MODEL_94354090bd78416db9cf92f08debe428",
       "value": " 2.03k/? [00:00&lt;00:00, 216kB/s]"
      }
     },
     "0eb91b78ec62413085ee5201b4879d51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "14c9332175744f2c9a87cf202b7e5e43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b7ea09b69a5c4eb0be88d6c27e036aa6",
       "max": 1,
       "style": "IPY_MODEL_93dcb988372c4c038e1bcc37e2dd8226",
       "value": 1
      }
     },
     "157cc3f6b2c44a9ab841e4a9e031ba28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "15c878f6a773439db5fa8a75cd351cba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "16fba7b2b0b44fc7b0e55498a2b81daa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "17beff982ed142ae9b9c16d43d562fe7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1cbba37269f14cb3adc6231aab94ec0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "27500f17fec24aba8e7acce8ea83d051": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "27f2a2c6bcd843f2aecccfc238e5aeba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "304c782600e34f4bbec20dd05bac2b8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "327f1899d69146a588146a2c1438932b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_304c782600e34f4bbec20dd05bac2b8e",
       "max": 125,
       "style": "IPY_MODEL_b90605e9c9194ce6a3ae4d7a6e45b938",
       "value": 125
      }
     },
     "33c05f4300414d429571eb86bb0745f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9d463ccb08314db7b739c050f75e26fd",
        "IPY_MODEL_844468e1c3a040e99f366285969e5f90",
        "IPY_MODEL_bf95c9d504ca4e23b38a93499056e9a4"
       ],
       "layout": "IPY_MODEL_70f71bc37d184dffbd97c1762be5ea01"
      }
     },
     "35ebeae515ce4f63b7f04fea02653beb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_60c4d3973130427abaccab5a3a8ab3b0",
        "IPY_MODEL_327f1899d69146a588146a2c1438932b",
        "IPY_MODEL_511bad69294648f4b30d169b6de0f839"
       ],
       "layout": "IPY_MODEL_07657f0e591f45b2bd6daea0bf3a709a"
      }
     },
     "382da22049af4fe4b18d64a0f5244a79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_05aa7474791d41f58c1dc859b1b4b595",
        "IPY_MODEL_dff246197adf485a8c3b3c68011b8cbd",
        "IPY_MODEL_7108e8e6568c4f6980efa3b4c0efda74"
       ],
       "layout": "IPY_MODEL_ff88d229f2d2434db0cdf1291c181755"
      }
     },
     "38d1ab6b9f2b47df9814fc090633d597": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3971f7e8987141e194253dda80c4762c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0eb91b78ec62413085ee5201b4879d51",
       "max": 546961866,
       "style": "IPY_MODEL_f7936bfa99334b87849ceed784bcd3d0",
       "value": 546961866
      }
     },
     "3a59711ccbb24883ab5a7f695e1ba062": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "40640803dbe04348ab036f33daf81b4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "46341794e83e4d9187a199b4a9441303": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "493d49e131bb4e02ad975058dca58fa9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "511bad69294648f4b30d169b6de0f839": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_99c659937cd54be599f5c86a4a22c272",
       "style": "IPY_MODEL_9ba367a1c8ae4a0b9a34904336134777",
       "value": " 125/125 [00:00&lt;00:00, 14.5kB/s]"
      }
     },
     "56d88dde3f464dfd9d271ac5d0f20d7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "57eb17cbc8d44b868069d858cd021405": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9b5d75bf975145949c2dd5b5ba7bdb60",
        "IPY_MODEL_b05a971007084bceb2265f052c92a5cc",
        "IPY_MODEL_6cb4ca7681e64c97b25295745d81e194"
       ],
       "layout": "IPY_MODEL_5b14eeacb2364983bf4670b0608cd492"
      }
     },
     "5b14eeacb2364983bf4670b0608cd492": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5b4e2172b5b24e01ae952be7aafdcac4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5c7aaa8c5f134376b8fad2f43af030a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "604eec8807aa4b06a5fe42234bc7179e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d920de03d86c4512b447cf6707c7efb7",
        "IPY_MODEL_14c9332175744f2c9a87cf202b7e5e43",
        "IPY_MODEL_aec323b29f264f4982b7e988497b1a56"
       ],
       "layout": "IPY_MODEL_8702fdecb4814a0d9f4baf15f5f0da7e"
      }
     },
     "60aff7390dbd46818324480f12ad4513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "60c4d3973130427abaccab5a3a8ab3b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b8f6b80bc88d444fb04a023dc43886b1",
       "style": "IPY_MODEL_38d1ab6b9f2b47df9814fc090633d597",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "6b68a295131a41c88d06f5c6d8afab4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f5d4bff4294741e292a9fab0668c85ea",
       "max": 1,
       "style": "IPY_MODEL_1cbba37269f14cb3adc6231aab94ec0a",
       "value": 1
      }
     },
     "6cb4ca7681e64c97b25295745d81e194": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c0564a9415dd44f2bff988810a9731f5",
       "style": "IPY_MODEL_7948a27fd3b546009183b758fc0b2e45",
       "value": " 711k/? [00:00&lt;00:00, 5.75MB/s]"
      }
     },
     "6e99844ded2a4556b73bdfa88028ada7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6ec643a0213447558ede33d184b19623": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "70f71bc37d184dffbd97c1762be5ea01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7108e8e6568c4f6980efa3b4c0efda74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_15c878f6a773439db5fa8a75cd351cba",
       "style": "IPY_MODEL_6e99844ded2a4556b73bdfa88028ada7",
       "value": " 1.19k/? [00:00&lt;00:00, 117kB/s]"
      }
     },
     "7359b63dba5f4151a63104635bcbc163": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ac035232183648cba7dfa94145c8ccf1",
       "max": 1,
       "style": "IPY_MODEL_6ec643a0213447558ede33d184b19623",
       "value": 1
      }
     },
     "7948a27fd3b546009183b758fc0b2e45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7df7adb5d0104bf6bc37138078bace38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7fa5ec81853f4c4e82ae9bfb4dffb7ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "82c743017aed423dae8778cdd386a35f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8308b345bbb34ccd9c21a88cf60384e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "844468e1c3a040e99f366285969e5f90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_16fba7b2b0b44fc7b0e55498a2b81daa",
       "max": 1,
       "style": "IPY_MODEL_7df7adb5d0104bf6bc37138078bace38",
       "value": 1
      }
     },
     "8702fdecb4814a0d9f4baf15f5f0da7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c32f66b479c41fc997f5f9b9a282b5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "93dcb988372c4c038e1bcc37e2dd8226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "94354090bd78416db9cf92f08debe428": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98ed2af3172148bcb25476428d4963cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "99c659937cd54be599f5c86a4a22c272": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9aa28fca4f24459f948bbca8c1cb4b16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "9b5d75bf975145949c2dd5b5ba7bdb60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5b4e2172b5b24e01ae952be7aafdcac4",
       "style": "IPY_MODEL_d6e79e878aa0452a9ae275ab1cdaaf38",
       "value": "tokenizer.json: "
      }
     },
     "9ba367a1c8ae4a0b9a34904336134777": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d463ccb08314db7b739c050f75e26fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_157cc3f6b2c44a9ab841e4a9e031ba28",
       "style": "IPY_MODEL_d85c9ba1a5554a6e9370b10644597a8c",
       "value": "modeling_hf_nomic_bert.py: "
      }
     },
     "9e5d578c3a7643dba785495dfac65315": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a7cea972468a4a1bad1fbbb94f6bf7ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ac035232183648cba7dfa94145c8ccf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "aec323b29f264f4982b7e988497b1a56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8c32f66b479c41fc997f5f9b9a282b5e",
       "style": "IPY_MODEL_46341794e83e4d9187a199b4a9441303",
       "value": " 1.96k/? [00:00&lt;00:00, 209kB/s]"
      }
     },
     "b05a971007084bceb2265f052c92a5cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9aa28fca4f24459f948bbca8c1cb4b16",
       "max": 1,
       "style": "IPY_MODEL_60aff7390dbd46818324480f12ad4513",
       "value": 1
      }
     },
     "b7ea09b69a5c4eb0be88d6c27e036aa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "b8f6b80bc88d444fb04a023dc43886b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b90605e9c9194ce6a3ae4d7a6e45b938": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bc35da3a38fa41698c4e3f26b031ead1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e943b49b288b4def8a9b3b4d88e16d2d",
        "IPY_MODEL_7359b63dba5f4151a63104635bcbc163",
        "IPY_MODEL_0649795efffb49ff8283a2534c5a1bc1"
       ],
       "layout": "IPY_MODEL_17beff982ed142ae9b9c16d43d562fe7"
      }
     },
     "bf95c9d504ca4e23b38a93499056e9a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_27500f17fec24aba8e7acce8ea83d051",
       "style": "IPY_MODEL_5c7aaa8c5f134376b8fad2f43af030a2",
       "value": " 104k/? [00:00&lt;00:00, 9.57MB/s]"
      }
     },
     "c0564a9415dd44f2bff988810a9731f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c28a0e0d07124ff2ab66cf36a03b6d9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_40640803dbe04348ab036f33daf81b4b",
       "style": "IPY_MODEL_d2daba2365f24d2f974122480f84f434",
       "value": " 547M/547M [02:37&lt;00:00, 8.25MB/s]"
      }
     },
     "c4b2327af9814da48d11f0b82b0e4e09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "d2daba2365f24d2f974122480f84f434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d63e8281ef764277a516d113d4236288": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d872c73b7cd94b77924438a9fa836c6b",
        "IPY_MODEL_3971f7e8987141e194253dda80c4762c",
        "IPY_MODEL_c28a0e0d07124ff2ab66cf36a03b6d9e"
       ],
       "layout": "IPY_MODEL_9e5d578c3a7643dba785495dfac65315"
      }
     },
     "d6e79e878aa0452a9ae275ab1cdaaf38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d743ed6416cf4e5d944aaf2486cc87f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d801c050ff6646e298fd3ff8fe3cf9fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f1fe162e231e4f63a378b94fb753af15",
        "IPY_MODEL_6b68a295131a41c88d06f5c6d8afab4a",
        "IPY_MODEL_0e9d2d36ac7d4242bce4bb490eaea8a5"
       ],
       "layout": "IPY_MODEL_efbba0499cc948e8965ecb0190af30a1"
      }
     },
     "d85c9ba1a5554a6e9370b10644597a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d872c73b7cd94b77924438a9fa836c6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8308b345bbb34ccd9c21a88cf60384e1",
       "style": "IPY_MODEL_27f2a2c6bcd843f2aecccfc238e5aeba",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "d920de03d86c4512b447cf6707c7efb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_98ed2af3172148bcb25476428d4963cb",
       "style": "IPY_MODEL_56d88dde3f464dfd9d271ac5d0f20d7d",
       "value": "configuration_hf_nomic_bert.py: "
      }
     },
     "dff246197adf485a8c3b3c68011b8cbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c4b2327af9814da48d11f0b82b0e4e09",
       "max": 1,
       "style": "IPY_MODEL_036acf673e8f45c6a264d40658edae8b",
       "value": 1
      }
     },
     "e943b49b288b4def8a9b3b4d88e16d2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f15ab6de2250429fb6edf477dfc27a47",
       "style": "IPY_MODEL_493d49e131bb4e02ad975058dca58fa9",
       "value": "vocab.txt: "
      }
     },
     "efbba0499cc948e8965ecb0190af30a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f15ab6de2250429fb6edf477dfc27a47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f1fe162e231e4f63a378b94fb753af15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0d10328fa0d94ad8b5f088811d9eadeb",
       "style": "IPY_MODEL_d743ed6416cf4e5d944aaf2486cc87f6",
       "value": "config.json: "
      }
     },
     "f4c8f8c5acf545bc95ef6f620d94a5b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5d4bff4294741e292a9fab0668c85ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "f7936bfa99334b87849ceed784bcd3d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ff88d229f2d2434db0cdf1291c181755": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
