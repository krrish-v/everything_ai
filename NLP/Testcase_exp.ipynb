{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzhCbLWuYMDz"
   },
   "source": [
    "## Qunatize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "whla8ZQqkuCT",
    "outputId": "b1b734a1-9069-4ce6-9b77-b2cdb4ddb822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Dpb_ef7YVg4"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Define the repository ID (Model Name)\n",
    "repo_id = \"Qwen/Qwen3-4B\"\n",
    "\n",
    "local_dir = \"Qwen3_4B\"\n",
    "\n",
    "# Download the snapshot\n",
    "local_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=local_dir,\n",
    ")\n",
    "\n",
    "print(f\"Model snapshot downloaded to: {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzNvfd2WvqLM"
   },
   "source": [
    "### 16 Bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "1085daf6d8f849499cabd6841878c02a",
      "bc1ca1adc7884b59a92da43f25423da1",
      "aa1515b5a8fe40b18b983229518b4c1f",
      "edaf7957a24849c688c9457d81dbc3f7",
      "8acdb3bb41664bb692706f06781639da",
      "8909b8614a054798a9464f14559518f7",
      "7a36a01fef3f4ac8be7ceb310d608f82",
      "5f8da1bf5a904e8a810dbf500d090fe5",
      "73a969c3854a4f9bbd3bc850ae622660",
      "71aca98adb534d80aaa4ebbf25b476bb",
      "8bdcd5c9ee3c4132a044b5132ac27924"
     ]
    },
    "id": "GxEhjpp2YX_4",
    "outputId": "5c7310f3-b8a3-4184-a47f-0633c7806fd9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085daf6d8f849499cabd6841878c02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"/content/Qwen3_4B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYykkp5tldJW"
   },
   "outputs": [],
   "source": [
    "def invoke(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # conduct text completion\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=3768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "    return thinking_content, content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJxE9clplmNP"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Your are medical expert and have the understanding of all the medical procedures\n",
    "\n",
    "Please provide an answer of my Query\n",
    "\n",
    "Note :\n",
    "  - You have to provide the answers in the two specific ways as mentioned:\n",
    "  - Scientific way\n",
    "  - Simple way (even any no medical person can understand)\n",
    "\n",
    "Output format:\n",
    "  - PLease generate a response in the python dictionary and it has to enclose with the code blocks astriks '```'\n",
    "  - Dot provide any other irrelevent text data other than python dictionary\n",
    "\n",
    "Query: A 65-year-old man with a 40-pack-year smoking history presents with unintentional weight loss, hyponatremia, and confusion. What is the most likely underlying endocrine mechanism behind his symptoms?\n",
    "\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NMNe22-mgnw"
   },
   "outputs": [],
   "source": [
    "thinking_content, content = invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HgTK1TbIoa1W",
    "outputId": "d616d3cc-fc13-4826-a629-d19356deaf36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "    \"scientific\": \"The most likely endocrine mechanism is SIADH (Syndrome of Inappropriate Antidiuretic Hormone Secretion), where excessive ADH secretion leads to water retention and dilutional hyponatremia. This can be secondary to a tumor (e.g., lung cancer) that secretes ADH, causing confusion and weight loss due to metabolic stress and tumor burden.\",\n",
      "    \"simple\": \"The body is retaining too much water, making the blood too diluted (low sodium), which causes confusion. The weight loss and confusion are also due to the effects of a tumor (like lung cancer) that's causing these issues.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOsBFiTMowee"
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"scientific\": \"The most likely endocrine mechanism is SIADH (Syndrome of Inappropriate Antidiuretic Hormone Secretion), where excessive ADH secretion leads to water retention and dilutional hyponatremia. This can be secondary to a tumor (e.g., lung cancer) that secretes ADH, causing confusion and weight loss due to metabolic stress and tumor burden.\",\n",
    "    \"simple\": \"The body is retaining too much water, making the blood too diluted (low sodium), which causes confusion. The weight loss and confusion are also due to the effects of a tumor (like lung cancer) that's causing these issues.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dehLSSmpDx0"
   },
   "source": [
    "### CHATGPT answer:\n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    "  \"scientific_way\": \"The most likely endocrine mechanism is ectopic secretion of antidiuretic hormone (ADH) by a small-cell lung carcinoma, leading to Syndrome of Inappropriate Antidiuretic Hormone Secretion (SIADH). Excess ADH increases renal water reabsorption, producing dilutional hyponatremia. The resulting low serum sodium causes neurological symptoms such as confusion, lethargy, and altered mental status.\",\n",
    "  \n",
    "  \"simple_way\": \"The symptoms are most likely caused by a type of lung cancer that makes too much of a hormone called ADH. This hormone tells the body to hold onto water. Keeping too much water makes the blood ‘watered down,’ lowering the sodium level. When sodium becomes too low, people can get confused, weak, and very sick.\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "> Add blockquote\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87vTd1aovtD4"
   },
   "source": [
    "### 32 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "5e6f754899c4423293ae0c17746b5d9f",
      "07d8ba36e1074f0cae28000c68ac84c3",
      "143aa5f8e091466999d907793217fe20",
      "ddbb9b1c535e4754a9a7faf79ee8a58b",
      "b36bf0fb2d6b46609c91650472441ede",
      "6aaab45abaae430aa93d120ae93e9942",
      "d2594ef328944549b2643a0a6164db9c",
      "db51bb671ef349a88e6b41c922290bee",
      "9dd62d8188b04c1da6e83c0838081a7f",
      "9d36bf3607ed4ff7895adc415646b089",
      "a0a57d2add424ae4b3fdf56664cf7bed"
     ]
    },
    "id": "I41630vLpGgN",
    "outputId": "b192d627-93fd-4498-feea-57777b2f42d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6f754899c4423293ae0c17746b5d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"/content/Qwen3_4B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5Gv3LKyvzTM"
   },
   "outputs": [],
   "source": [
    "def invoke(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # conduct text completion\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=3768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "    return thinking_content, content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iF0S3xcpv2gB",
    "outputId": "e8895a8b-876a-4642-f4c5-31805464a618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "    \"scientific\": \"The most likely underlying endocrine mechanism is Syndrome of Inappropriate Antidiuretic Hormone Secretion (SIADH), secondary to a small cell lung cancer (SCLC) tumor. SCLC, which is associated with a 40-pack-year smoking history, can secrete ADH (arginine vasopressin) or other peptides, leading to excessive water retention. This results in hyponatremia (low sodium levels) and cerebral edema, causing confusion. Unintentional weight loss is due to the metabolic effects of the tumor and cachexia.\",\n",
      "    \"simple\": \"The man's symptoms are likely caused by a tumor (like lung cancer) that makes his body retain too much water. This leads to low sodium levels and confusion. The weight loss is because the tumor is using up his body's resources.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "thinking_content, content = invoke(prompt)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1ubRowA3_sW",
    "outputId": "21672fca-0fc9-4613-ba8d-153b4f7d645c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "pip install -q accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vc5jT-LZ5IYe",
    "outputId": "0a8a9af4-108d-4051-b17e-6f3925d6cfe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nd-bEona5UAf",
    "outputId": "315a1eda-4a2e-4f43-ca22-914a7bbbfe6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: bitsandbytes\n",
      "Version: 0.48.2\n",
      "Summary: k-bit optimizers and matrix multiplication routines.\n",
      "Home-page: https://github.com/bitsandbytes-foundation/bitsandbytes\n",
      "Author: \n",
      "Author-email: Tim Dettmers <dettmers@cs.washington.edu>\n",
      "License: \n",
      "Location: /usr/local/lib/python3.12/dist-packages\n",
      "Requires: numpy, packaging, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hd6SH1mO37Td"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "config_q = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549,
     "referenced_widgets": [
      "ffea410d3ddc44eab867b423bce83ae0",
      "a1da05e6221c4db1b753aea04a3fa881",
      "06fd4cc619b0407f8e0a605676bd6220",
      "34d6c216551c42d182681e9647c6f57e",
      "937a84b68baf4146a1407ca1dad3431a",
      "68ae8f55b91648c48efc5c578e54e569",
      "ccc95e663e4449e7b61f188e7b38397f",
      "a832968fa30e4df980f2e1ef31973d50",
      "24f217ccfcb342059ca995092caa6c0b",
      "da0c9e2302e94c8d8a9c7cb0156280d1",
      "fb486ca3b5264ced90ad311bb4739418"
     ]
    },
    "id": "CDSGtJvs4RIY",
    "outputId": "ac55776e-4694-4d30-c08a-36323ac22edc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffea410d3ddc44eab867b423bce83ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=2560, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=2560, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2560, out_features=9728, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9728, out_features=2560, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"/content/Qwen3_4B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=config_q,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxLsOcU2457D"
   },
   "outputs": [],
   "source": [
    "def invoke(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # conduct text completion\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=3768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "    return thinking_content, content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkpnGxz65f8o"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Your are medical expert and have the understanding of all the medical procedures\n",
    "\n",
    "Please provide an answer of my Query\n",
    "\n",
    "Note :\n",
    "  - You have to provide the answers in the two specific ways as mentioned:\n",
    "  - Scientific way\n",
    "  - Simple way (even any no medical person can understand)\n",
    "\n",
    "Output format:\n",
    "  - PLease generate a response in the python dictionary and it has to enclose with the code blocks astriks '```'\n",
    "  - Dot provide any other irrelevent text data other than python dictionary\n",
    "\n",
    "Query: A 65-year-old man with a 40-pack-year smoking history presents with unintentional weight loss, hyponatremia, and confusion. What is the most likely underlying endocrine mechanism behind his symptoms?\n",
    "\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbjXUSS25BwS",
    "outputId": "b0e41175-63b4-4d73-96ed-9c0fb1835584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "{\n",
      "  \"scientific\": \"The most likely endocrine mechanism is SIADH (Syndrome of Inappropriate Antidiuretic Hormone Secretion), caused by small cell lung cancer. This tumor produces ADH, leading to water retention, hyponatremia, confusion, and unintentional weight loss.\",\n",
      "  \"simple\": \"The body is making too much antidiuretic hormone, causing the body to hold on to water. This lowers sodium levels, making the person confused and causing weight loss, which is often linked to cancer.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "thinking_content, content = invoke(prompt)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsyRsH3C5_y8"
   },
   "outputs": [],
   "source": [
    "```python\n",
    "{\n",
    "  \"scientific\": \"The most likely endocrine mechanism is SIADH (Syndrome of Inappropriate Antidiuretic Hormone Secretion), caused by small cell lung cancer. This tumor produces ADH, leading to water retention, hyponatremia, confusion, and unintentional weight loss.\",\n",
    "  \"simple\": \"The body is making too much antidiuretic hormone, causing the body to hold on to water. This lowers sodium levels, making the person confused and causing weight loss, which is often linked to cancer.\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2zz4bZTTlGH"
   },
   "source": [
    "## Embedding model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jhDVHPPbgmVA",
    "outputId": "18c8a38a-cef4-425d-823a-52b8791c0ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.36.0)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-huggingface) (0.14.10)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-huggingface) (5.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.6)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.5.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.12.3)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.17.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.9.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.16.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.22.0)\n",
      "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.11.12)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
      "Installing collected packages: llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.6.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "a26b933215d44bd6964808c24688e7e9",
       "pip_warning": {
        "packages": [
         "llama_index"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OV5gukYabnUN",
    "outputId": "c592cddb-255e-4743-ce3e-c072ec76c0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/11.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/11.9 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m9.5/11.9 MB\u001b[0m \u001b[31m138.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m202.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m764.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m848.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0ADhxaAgl8s"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee5ujqSPhtvu"
   },
   "outputs": [],
   "source": [
    "all_mini_v2 = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cuda\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "c0aca7b5a8f4493c98769a94b7a56a24",
      "d294a784530547d49748c64b9137514e",
      "5559d82ff03f4a4aad5527afaf4a89ae",
      "f944b26f0775441a95ae43309915daed",
      "fad8edf57bf34807b398c2cb5c851252",
      "2d176f4f296a48f3bc4501f42ad96721",
      "915b1a4147e4457fa5bd970e4d149450",
      "c38b51025a7e48c3bcd1c6b007c927d7",
      "972ed83de27b46f39ee8190f7dbcde16",
      "7b0878bfc371430290ebffce1c06cd93",
      "1287913df1334805bafcb49777e2f740",
      "964197cba85d4ca49fd63a989bca5c1d",
      "116c59f2cf6643b7b16c379b8bf474a8",
      "203a8c6ee2bc4ad78e8369e83c8397b5",
      "21159fcce26242e38ffc2699d2d94b30",
      "284938585c854cd6b99ce3b28cdcc363",
      "33a977ec2a13424fbd9d516b4febe702",
      "6a26ecd7b158428192a1586a87052373",
      "f343e962b11a4340975b3c7342668d58",
      "42c69f8549cf4ab69e65da4b394269d5",
      "284fce0e739f4e97b2fd23c24e120a53",
      "ae086f5b061744e7926b37ab1cdef964",
      "474ded7fe8e14dae8e3f406db149336d",
      "9fe97f2f91a7492285db96b5dafc4934",
      "ef3eed5806c54f9fa5f662e3f85e885d",
      "b263719045404464b21897ec54d870df",
      "8932d9588fff4fa5ab203bb66ef6ae39",
      "ef2c0e01d93947fda4ed8db7565756ec",
      "5e249c7c38e2470794668fffadde7756",
      "99575e2af2294c91920221465e84f7af",
      "f7aaa744882e4edf94a4bd6e6e5ca0a0",
      "3f759957f8a44254afc79a8f23c45315",
      "e6687c6ac6e040c09798241c95cea03a",
      "153d03f97ab94e91a89675e2a27b8792",
      "9aa502ba7e734931b09f9b6949441e9e",
      "39c1188883e14bd89f4a3dad703a76a8",
      "2e4662664414493a83f20845ec406c7d",
      "bdc169535eac46f19a1f94b974b4043a",
      "c3704dc45c134f75a5b5c2f1e4aae5be",
      "42c204ae38d24ee79f7cba3d1543d4e6",
      "de019d04e72a462b90a18895675c87a9",
      "f20886d6f5d442fbb5f8942c806b13fd",
      "ddacc4642e64401b96f596a4463a0713",
      "cda99ecefc01488e876328b85789650e",
      "50413b0989df4ca0aef55da5420434fb",
      "12cc03c76c5b446b9309a635cf896c53",
      "196271c10178496987c3aaa667051af3",
      "c3cd51025acf4948ba75c2e310cee4c7",
      "4c3eca0814c24294b0d34dea52a1c142",
      "64fccd45bee54ddfb7fe3a867315ce69",
      "0c7b1ff3a6fd4b7ab752030ddf435fa0",
      "b2a2bd1bd01143ff82b7ad7eecd6e2d8",
      "db05d2247b3a432a9233a77a9d522b9d",
      "123c99ddf7464ad7aa32bc95b6987b24",
      "0cd329d865ca42da8c14555074bc10e4",
      "4d78ac9856c0482392206c98c0c5eed3",
      "a8a636f287c543efbf9c97f0eb56cd58",
      "461ee20a16794d6a84451d62f1bd6241",
      "1dd4b3837dbb4dd596a20959e271b67b",
      "320f8130bf7f4cc9b140021b75c6e593",
      "d804dd523d33439c97a90b68de2998c1",
      "dafc84ea0aad46ffa8979c3b9c39776e",
      "71883e9dc68e4813b28c872583859152",
      "c12e17a5c54f41e0919d141ba33e30f4",
      "6bba6f4fe4bc4426bc9f006882d0e942",
      "5a9fb0af579a4820b631f1cfe7a1c06c",
      "8143e4f23d994fbd91d3863ce752e7f7",
      "a917e2f73bfe427cad6044005beb759f",
      "5b768c3e5c40460ba947905d65ec9878",
      "01ba5fcc40c4485394c836dd20d5ac3e",
      "b7b7868122794c66bcb7a521f46b1caa",
      "5e90c1b805904410b2bec7769153dfd5",
      "5d25519950554e64b15045190f0b131b",
      "6f6ecd1383ce4c2ab54d991863a7b4d3",
      "85d4e12382c649f4be520984b8a5d91f",
      "5b2edf73c8814ff08eb7d71c60c3beb3",
      "bf47796e6bbc4c859021e07b587ecede",
      "715de9599ee1470f9b4ea97033200b96",
      "90fa76ac74684c1895d3774fd68918f4",
      "df130ea5d01248d69f04d7447c0860cc",
      "d92b5165fa8b4f87be78a16553c680dd",
      "21ea5d81fcad4d68a1e007a9ad4c1d86",
      "7c7514a06925443f8a35d7bfd407b105",
      "d04a2f6abff641b6997018a020790ce9",
      "aae5190bd77247eda2f6d1e21e869698",
      "32788b963ceb40719fa87e78bae90532",
      "6739a2bfdd5e4902af1c9aa2d8cb792b",
      "8cb3f74f81244b269547fb9496506a8e",
      "6e32062f08e44e809971d4eba9e0ccd2",
      "c3138c49aeef45f886e8d296e1e1d72a",
      "e861852e042b4eafa73efc4a2d069e98",
      "ccfb7c6cf86e4aefb6b9ab8d8f66da08",
      "f0642718648c457eb738a7d5b369155a",
      "eddfebedb40d402792e8d3e1e86c0e93",
      "5d776bfde3184b05829867593af4a47d",
      "25ef369ee5eb4eb29062381783e0558d",
      "9f7806f2758e40deb23a06e4c4a1e3dc",
      "5cdfe2d497b54c91ae971b525636249a",
      "4a75cefe70d5443c9054a554a343cec0",
      "8c91db82d0f1487987c7354a1278ba8f",
      "dca413b9f72141feb755da6c1684c7a5",
      "3cbfd45643194163beabe5c6493ce6fa",
      "0f126973dfb544599edb2f7ec42b67b2",
      "ab2d37a46475484e968fe353b94f8fc9",
      "ec05c0c6686c4949bd33c785e9bf5b3d",
      "397f54ad37c746c5b6a559a03fcd4d85",
      "bc5fe32137f54b1d93dc5b02f7534b03",
      "2c4b370bd92d435d941f11f9b985dbd7",
      "1cc634b2a8954531a0682f55cf90fee7",
      "e67cea7ea2174bda9d6257b6aced4aec"
     ]
    },
    "id": "Txn0Fz_Uh1jv",
    "outputId": "b4023c33-a887-4d9f-a4ae-7eac448e2788"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0aca7b5a8f4493c98769a94b7a56a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964197cba85d4ca49fd63a989bca5c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474ded7fe8e14dae8e3f406db149336d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153d03f97ab94e91a89675e2a27b8792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50413b0989df4ca0aef55da5420434fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d78ac9856c0482392206c98c0c5eed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8143e4f23d994fbd91d3863ce752e7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715de9599ee1470f9b4ea97033200b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e32062f08e44e809971d4eba9e0ccd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c91db82d0f1487987c7354a1278ba8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qwen06 = HuggingFaceEmbedding(model_name=\"Qwen/Qwen3-Embedding-0.6B\", device=\"cuda\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529,
     "referenced_widgets": [
      "b9b0aba589f6423e8ba186fb3e37b9d2",
      "1522ba00fd2144e3950a3aa63b352a2f",
      "2e0dad995e9640df87d2c73a9774cb35",
      "8a309f6f58cf486ea1edddf40b18536c",
      "42eec9b683b84371bfba2e40a5a55662",
      "1399eb038aea4b259af154263779409b",
      "56e21b38af064ba8838bfc0154baad52",
      "c228fca6806a48da97b7b645d5d4c657",
      "87ca6bd1902040969019f5cc127d310a",
      "4c4ae46acfb64c34aa059bd74f076049",
      "ae3dc44bd0454da4930dc33f7ef4059e",
      "109163518a314f7fb7784962efa8fed6",
      "291ba236b5b6481eb2735863a1c62c59",
      "8ef8b1ef5b7d475bb7e82cc3403897be",
      "8fb096972d254bf4a4367d75328465ae",
      "f96611fab89a475ea6c3c427576fbd0c",
      "22ee95b0d5a04eefa15f971f798658c8",
      "336ada8ebcf64f188cf37caef839656f",
      "0f762cd9de0246eeb6524dcba6e00440",
      "6863f4cfee0049c6a56926ab8c84f467",
      "a2d88e687a9e47adb01f7ba39065aac6",
      "b2b08010e78646dbbf6a2a7594b881db",
      "3cd65adef85e461a825cb1cd3c83115f",
      "ebcd1e47f7774daeb22a855224b1478b",
      "8a8f069cc6ce48e38130c2a53a7db7cd",
      "8d9195408aa148eb93a1c6151c6ad8e6",
      "2cca3185331e4b78aec7baa8921bdbf5",
      "273283b1bd45480991c209ff88b367c8",
      "18b2bbf427974a6abd17074cf65d2213",
      "dbf1b5bde62a454abcb967fdeb13e418",
      "037f581b13aa4535946f3c225212bff1",
      "baa47d6f1f5843e3955fff89aad31a92",
      "2cea3dff903a4361a052a457b944048d",
      "bded93aa030d4c1cbfb9268394930e24",
      "6ba19373b5c44ad7af6c4baab2848e39",
      "e668f7485ef3493f9c732baa11a6df7a",
      "7e28d43c9f2b4468b657d705ceaf10f1",
      "e40ebe0a50354d22ae26395da5bab6cd",
      "7c2ec02c2c4a4b20a3a82cfb4063177a",
      "84a0c5f06f744ed68169534045ec9700",
      "bf159ebd2f764a41a9827f2c3b36bf20",
      "bdec4026a5fa4092a18c8e1a684548bd",
      "833a1bb929af4b379f85df3d922b136c",
      "2cad17c2aaec4de895487b59779abcf6",
      "6f17bef942684e54895c81d57ebdfdd5",
      "550a36373ac247fd945868e7fafe1f42",
      "a71fc34fb48f4e7cbebb87bc1db90e8e",
      "16c38fe2112a407cbf468d38752c3c04",
      "6132ec312e31432cb328e99613ad088f",
      "88d0851934404755bedfdab14065f9ff",
      "b8e203b3ce1f437f8ae144498f034cd8",
      "b3e547db465a45338bc9fc2d6cb434ee",
      "caa6a61da516494e8fae9d565cefc36a",
      "218c83b1ced943158a5a435bd046ad85",
      "e8d8d231ff934b5693fc862b96f2e16d",
      "296a2200aab64c6db481e901c56f880c",
      "946b15cc832e4fbfbede4b7422868940",
      "ccd828d68d7b48d68ab7a8b5aa168891",
      "8f04604648114c8e8bd37a7ecbb87a08",
      "4e4cece6d97f45e78e970313b04083db",
      "ada71a90dcee4dce9faec9e5a05ab86f",
      "cd73734c1ad24bc89b3d03e97224f261",
      "71eb626b16914ddbb787657465d72705",
      "002ee3a2cf4448bf8235f12ea1ac7f13",
      "43256c0f2a564c55ae910a3c5aa94d94",
      "23cc7385d7cd4d209ec75e523c222599",
      "65aee8668e6145e3a5429d15665074bc",
      "d84a71713c1e4d79b8cc96989c1010d4",
      "1ccb4c1f37dc4bf59559488e2ebce0cf",
      "983b190bc19f4bbda79f65cbc822085d",
      "c85fe6cebb2042d98e524ca5c8ac8b1a",
      "4d3638503e0c40b8b7d18f514fd888ca",
      "4a8fc09f27104b2198957ebc30c7c600",
      "5a8f9e70211f40719c0a5a50999ba2eb",
      "9ca1b77d816549a98dea2bee63c636fe",
      "078745bed3d040e2bde35d5c9fb19693",
      "51a3e94018fd4a1698931974bda43c27",
      "2a1691363b6143089ebcfdb05b71ea94",
      "48f65052ade2408ea2dc809fc8af1e70",
      "4b177b3fa68745168f98b1bf50702571",
      "1620d4bd6b1541f9aa0662af241afad3",
      "e1ccb89f80314994ac3d9426ee4232b9",
      "0c7ad67b3c9d4b9d9c976819ef9e588b",
      "89d67747ac4445c695267ae6efcae80e",
      "c39b7e6c5a68426f9dd68fe748c97b5e",
      "00497d88137c4cfd980dec34c00eb2b5",
      "f3a1c46d30ac4df786f410b129aad6d4",
      "ec8a8852f4474cbe9c8f930ee506fb8c",
      "53584d3d599b4c5baab492ce926e7555",
      "855adaaf4b064e8fb52f447ce81db038",
      "a522a2eca9544c7abccc1402ba4cac70",
      "11c9783757d44876b1be91347f829721",
      "c445d11408f14b5a81eef0c327c4419f",
      "8a9db5b094f54447a719b0767f3168df",
      "5f098c1e2493496096cb1487f1e7b8fc",
      "e91c258cbfb446348f9473fea51fa3da",
      "9a9f7e9faf5247b9b2c8ba4ccb67b633",
      "55b4c0d0eafb45578d4013183299e670",
      "315d352f0d3741b2beed282521574789",
      "e4dbfaa43d7344d8ae642294022331a6",
      "a3d583fca4f04edb96e4fe1224a8f090",
      "925691ef126042d3bc588faf9c454323",
      "426eae2d911b4c4fad62c1f2dde50ba6",
      "76dbce6d979b45f1a1b4068497bdf3da",
      "c13d22434f2b4318bb56b96aca1b4e51",
      "ddef255e86d648eca1da8f928dc74772",
      "84f84788c90f482d9c9739e16c31ea6d",
      "22d2024e98a94ad49d2f483cd576f17a",
      "1222a3b6b2834a039b63dff11d8605d8",
      "ed7c6a602da64709a38ee29d40ba748c",
      "caa31e03238b42349d34fe62a2c6389e",
      "93c88b66d32649eda57647082cfabcfd",
      "9b10c9c55aa24e0c8a583332e97be597",
      "f56f55f506844568ba3f0f99dc17b595",
      "83d497062c704962817b2091f515c5d5",
      "0bd2efeac0184df3bf216e347a2a4dc4",
      "4a6e9b5c9dda45cbaf7f5f5fba86e14b",
      "88e7d8e6648249ce824920ab0296b33b",
      "d2fd1450dd5f4e0da4f519ea20b72bfa",
      "2871b4d5ffb04ebcafd343592482ed5f",
      "cc8c994bca2043caa555164ab62c1f1e",
      "e9f27076e8184d75a961e40aa102c4ed",
      "86980e2cbfe6416d956a6f2cdca2b1cb",
      "e8457347469b4e70b15eaf9fb1515783",
      "1872478685574d549aee15f92feccd28",
      "c9aeb74edae54b1a85a1611bbbc30abe",
      "1e50bd715318477593a39e09c1c5ae6b",
      "893728ed84e843689695680a1c993fe2",
      "c39853cb4bf6427cb9ac46eea65a04d8",
      "9bcb95973b0f4351a7f2da9ef3538c38",
      "555f70bf1b4742f9b3f0aa1d12226e20",
      "c2e361eeed914cb1afa128db5cf0b6e9",
      "1339b59fa2274f068a09ef8c686f0d21",
      "58d3a3071bc948e98518303b85515853",
      "4088978c6f9a4d86bb8d3f610ff019b6",
      "02efd0f649fa4fdd9531c4e5bb20be51",
      "57fb315fd31d4d098bfba3522f7554a4",
      "9fb985e071814e57b788ba095a108d90",
      "8e8b6048013c45318028c9eea245f616",
      "00085fa96e1a44abbdde7a5086980f2d",
      "96db05d15aee4ed48614bf93ac6d812a",
      "88f47a6376fd4ec591b8d49ca7bb15f7",
      "252a9b9a3d714821b039c5d8b0616424",
      "7ab725fbf29241b9bebe1dd7016d338a",
      "93b23330b54b436b9f82f7e9227f87df",
      "96c2da3740a5498db9bfb8de208ede7d",
      "bb151b88b7464f2ba9ac3942f5719bc7",
      "a835328b7e46481684f4ee4018b2b562",
      "fdc4fc791c4a4a7ebce088119be30505",
      "442a875e32994c1ba21898f90d8bee19",
      "f6924bf8fa964676b026ff7115ab5f29",
      "371551bcad444d34800fd7ca162fc002",
      "cebef184f2364cbb89fd68343c29866f",
      "e776633c9f1f4a62b9f8ad8f1ced466b",
      "9cb41e53c1f645a59f3904f38e056208",
      "73f29d632d5945cfb348fb4edeb4ec44",
      "9d4516a602264f1fbeb6cb4e9b90172b",
      "f19f1d294b9a493ca8b1ed902f518f0d",
      "528cea71992e4a618ef0c2511b39b4cd",
      "da21f639f113492198f447843d5dd074",
      "2af66dda540149478db12a312b5e3602",
      "9417cecf95474bba9b0a4ec703a39ec8",
      "e678dbd392194a569e95ea572ddd7012",
      "70ce31c8f9ca4b29a97449267b5515dc",
      "06f77435f6514d6bba44776b69637bf9",
      "53c9cee87b9e4eaf99373bd49ecae49b",
      "9ec27268b8974f1b94b2ee5cebd664e3",
      "c6debaf547dd445d8171f333c1499e5f",
      "d697c0d59a2a4da39550ade28508ae4f",
      "714099b9d8c54110adca29d8771dd229",
      "ff980b71df2241268af212663c38bb58",
      "369989a2f03b4129b9355b5a9dd4dce4",
      "b8055a7cb0d7411e95eaeeb190a8c200",
      "dc7840bf6d494c9091c91dc07cc736c0",
      "a4cd5d621d3a4c70ac22e20d5399262c",
      "7cdbdf97e30c450a971b5641e88bfdfa"
     ]
    },
    "id": "yng3JT8niCr3",
    "outputId": "e87f3e17-917f-426f-adef-c4805efd1d86"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b0aba589f6423e8ba186fb3e37b9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/573 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109163518a314f7fb7784962efa8fed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd65adef85e461a825cb1cd3c83115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bded93aa030d4c1cbfb9268394930e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f17bef942684e54895c81d57ebdfdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296a2200aab64c6db481e901c56f880c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65aee8668e6145e3a5429d15665074bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1691363b6143089ebcfdb05b71ea94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53584d3d599b4c5baab492ce926e7555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dbfaa43d7344d8ae642294022331a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa31e03238b42349d34fe62a2c6389e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f27076e8184d75a961e40aa102c4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1339b59fa2274f068a09ef8c686f0d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab725fbf29241b9bebe1dd7016d338a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb41e53c1f645a59f3904f38e056208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c9cee87b9e4eaf99373bd49ecae49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemaa = HuggingFaceEmbedding(model_name=\"Leonardojdss/my-embedding-gemma\", device=\"cuda\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62Qsd-lxTorw"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Cooking is a beautiful blend of creativity and precision, where simple ingredients transform into flavorful experiences. It’s not just about following recipes—it’s about feeling the textures, smelling the aromas, and adjusting each element to match your taste. Whether you’re sautéing vegetables, simmering spices, or baking something warm and comforting, cooking becomes a form of expression that brings both joy and nourishment.\n",
    "Aerodynamics is the study of how air interacts with moving objects, shaping everything from aircraft flight to the design of cars and sports equipment. It focuses on forces like lift, drag, and thrust, and how the shape and motion of an object influence these forces. By understanding aerodynamic principles, engineers can create structures that move more efficiently through air—reducing resistance, increasing stability, and improving speed. Whether it’s a jet soaring through the sky or a cyclist cutting through the wind, aerodynamics plays a crucial role in making movement smoother and more optimized.\n",
    "Quantum physics explores the strange and fascinating behavior of matter and energy at the smallest scales, where the rules of classical physics no longer apply. In this realm, particles can exist in multiple states at once, teleport information through entanglement, and behave both like waves and particles. Quantum physics helps us understand the fundamental structure of the universe and powers modern technologies like lasers, semiconductors, and quantum computers. It reveals a world that is unpredictable yet governed by beautifully complex mathematical principles, challenging our intuition about how reality works.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtICPfjgd7sa"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    SentenceSplitter,\n",
    "    SemanticSplitterNodeParser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECbGdJFEeR4-"
   },
   "outputs": [],
   "source": [
    "splitter_0 = SemanticSplitterNodeParser(breakpoint_percentile_threshold=85, embed_model=all_mini_v2)\n",
    "splitter_1 = SemanticSplitterNodeParser(breakpoint_percentile_threshold=85, embed_model=qwen06)\n",
    "splitter_2 = SemanticSplitterNodeParser(breakpoint_percentile_threshold=85, embed_model=gemaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmXPibWzfWLD"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yo7raEzYfX1X"
   },
   "outputs": [],
   "source": [
    "docs = Document(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uNaOCaGj0Uz"
   },
   "outputs": [],
   "source": [
    "chuck_minilm = splitter_0.get_nodes_from_documents([docs])\n",
    "chuck_qwen06 = splitter_1.get_nodes_from_documents([docs])\n",
    "chunk_gemma = splitter_2.get_nodes_from_documents([docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qV_HiRvQkIW4",
    "outputId": "1f517a19-f3c8-4b89-a008-e87e3961d79c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cooking is a beautiful blend of creativity and precision, where simple ingredients transform into flavorful experiences. It’s not just about following recipes—it’s about feeling the textures, smelling the aromas, and adjusting each element to match your taste. \n",
      "\n",
      "\n",
      "Whether you’re sautéing vegetables, simmering spices, or baking something warm and comforting, cooking becomes a form of expression that brings both joy and nourishment.\n",
      "Aerodynamics is the study of how air interacts with moving objects, shaping everything from aircraft flight to the design of cars and sports equipment. It focuses on forces like lift, drag, and thrust, and how the shape and motion of an object influence these forces. By understanding aerodynamic principles, engineers can create structures that move more efficiently through air—reducing resistance, increasing stability, and improving speed. \n",
      "\n",
      "\n",
      "Whether it’s a jet soaring through the sky or a cyclist cutting through the wind, aerodynamics plays a crucial role in making movement smoother and more optimized.\n",
      "Quantum physics explores the strange and fascinating behavior of matter and energy at the smallest scales, where the rules of classical physics no longer apply. In this realm, particles can exist in multiple states at once, teleport information through entanglement, and behave both like waves and particles. Quantum physics helps us understand the fundamental structure of the universe and powers modern technologies like lasers, semiconductors, and quantum computers. It reveals a world that is unpredictable yet governed by beautifully complex mathematical principles, challenging our intuition about how reality works.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in chuck_minilm:\n",
    "    print(chunk.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJMucxVXkPXL",
    "outputId": "185a0042-2038-4364-bbd6-370be1f36d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cooking is a beautiful blend of creativity and precision, where simple ingredients transform into flavorful experiences. It’s not just about following recipes—it’s about feeling the textures, smelling the aromas, and adjusting each element to match your taste. \n",
      "\n",
      "\n",
      "Whether you’re sautéing vegetables, simmering spices, or baking something warm and comforting, cooking becomes a form of expression that brings both joy and nourishment.\n",
      "Aerodynamics is the study of how air interacts with moving objects, shaping everything from aircraft flight to the design of cars and sports equipment. It focuses on forces like lift, drag, and thrust, and how the shape and motion of an object influence these forces. By understanding aerodynamic principles, engineers can create structures that move more efficiently through air—reducing resistance, increasing stability, and improving speed. Whether it’s a jet soaring through the sky or a cyclist cutting through the wind, aerodynamics plays a crucial role in making movement smoother and more optimized.\n",
      "Quantum physics explores the strange and fascinating behavior of matter and energy at the smallest scales, where the rules of classical physics no longer apply. \n",
      "\n",
      "\n",
      "In this realm, particles can exist in multiple states at once, teleport information through entanglement, and behave both like waves and particles. Quantum physics helps us understand the fundamental structure of the universe and powers modern technologies like lasers, semiconductors, and quantum computers. It reveals a world that is unpredictable yet governed by beautifully complex mathematical principles, challenging our intuition about how reality works.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in chuck_qwen06:\n",
    "    print(chunk.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liTtWU-Dk9LB",
    "outputId": "794639d3-39bc-4544-eb40-5d8f2fd369d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cooking is a beautiful blend of creativity and precision, where simple ingredients transform into flavorful experiences. It’s not just about following recipes—it’s about feeling the textures, smelling the aromas, and adjusting each element to match your taste. \n",
      "\n",
      "\n",
      "Whether you’re sautéing vegetables, simmering spices, or baking something warm and comforting, cooking becomes a form of expression that brings both joy and nourishment.\n",
      "Aerodynamics is the study of how air interacts with moving objects, shaping everything from aircraft flight to the design of cars and sports equipment. It focuses on forces like lift, drag, and thrust, and how the shape and motion of an object influence these forces. By understanding aerodynamic principles, engineers can create structures that move more efficiently through air—reducing resistance, increasing stability, and improving speed. Whether it’s a jet soaring through the sky or a cyclist cutting through the wind, aerodynamics plays a crucial role in making movement smoother and more optimized.\n",
      "Quantum physics explores the strange and fascinating behavior of matter and energy at the smallest scales, where the rules of classical physics no longer apply. \n",
      "\n",
      "\n",
      "In this realm, particles can exist in multiple states at once, teleport information through entanglement, and behave both like waves and particles. Quantum physics helps us understand the fundamental structure of the universe and powers modern technologies like lasers, semiconductors, and quantum computers. It reveals a world that is unpredictable yet governed by beautifully complex mathematical principles, challenging our intuition about how reality works.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunk_gemma:\n",
    "    print(chunk.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSHHty19wKO6"
   },
   "source": [
    "## Image to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pl2Mb_R-pQz"
   },
   "outputs": [],
   "source": [
    "https://huggingface.co/collections/nvidia/nemotron-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eFDA05lwxhc"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqD3kKrGzIOE"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENcoK0Kr0wCt",
    "outputId": "3b44c190-54c9-4960-d64b-022bf4d1b5e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): \n",
      "Add token as git credential? (Y/n) n\n",
      "Token is valid (permission: read).\n",
      "The token `model_access` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `model_access`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fcJyPcm0Yk7",
    "outputId": "dd6a61b6-73cc-4431-9e11-151ab045f930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for hqq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q hqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4yEOwJB0VED",
    "outputId": "661431b7-2881-41f4-da38-ef87f84552bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
      "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import hqq\n",
    "from diffusers import Flux2Pipeline, Flux2Transformer2DModel\n",
    "from transformers import AutoModel\n",
    "from hqq.core.quantize import HQQLinear, BaseQuantizeConfig\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JI7G-V0l0hHz"
   },
   "outputs": [],
   "source": [
    "def replace_with_hqq(model, quant_config):\n",
    "    \"\"\"\n",
    "    Recursively replaces nn.Linear layers with HQQLinear layers.\n",
    "    This must match the exact logic used during quantization.\n",
    "    \"\"\"\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            # Create empty HQQ layer\n",
    "            hqq_layer = HQQLinear(\n",
    "                child,\n",
    "                quant_config=quant_config,\n",
    "                compute_dtype=torch.bfloat16,\n",
    "                device=\"cuda\",\n",
    "                initialize=False\n",
    "            )\n",
    "            setattr(model, name, hqq_layer)\n",
    "        else:\n",
    "            replace_with_hqq(child, quant_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qbcCuLX0iLO"
   },
   "outputs": [],
   "source": [
    "\n",
    "hqq_config = BaseQuantizeConfig(\n",
    "    nbits=2,\n",
    "    group_size=64,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405,
     "referenced_widgets": [
      "4b4cbb2b4e154cf8839e43f54db6ccbc",
      "269f9450c1d2461a9dc155650cb880c9",
      "0c57d57cc26a4dc48f63f99542165b5b",
      "630729bbf6ef4f15b73f7f6de3a1ac9c",
      "ea7af06e3edf4535811c669837266fe3",
      "29ffeeb3249b42b2b43a2e1be4b0feca",
      "60ac1f701c3b401ebdbb6822b62dbb2c",
      "2d69b55a753c4a688a76e834fc0888ac",
      "1967093b81a94185ab4ae4823202e2f3",
      "483b74d36bae46a9a754884969afed68",
      "ba7b3f2e0c774f898b26a480a0319879",
      "b07052df2bfa42e99838c7cef6e98945",
      "f5a9e001cc2c4b5fb871bc5f40aea6e6",
      "33275e3dd06044d886dd56c96e57a36c",
      "51c9fbd6696745778dc3eb7cfe7ad2f8",
      "36ca37bdbfe5464bb3726cd34415c8c5",
      "1d4d0b8b2cf443c196554c307469c27d",
      "fa05672016114360b89fd1b79b1e9ab5",
      "807a22ca279f432585d07d9b5ec2860b",
      "399d41f22f034117a6a825777c370c63",
      "d740da2bfa784aa1a7e7fedd33d40fc0",
      "cec5517a9cd5411aaf87f47a039a69fe",
      "5845d10c18df4f12b5f2b86006a8aade",
      "800f41e9939f4aefb08c6f3188351e65",
      "b34b806a7ca04eaab0087ecc9193e5aa",
      "bc6081c1a0e0448eb5260414e18edacc",
      "8191a3f712264a4eb5e338de2c4fba2e",
      "0405bc3ce54841d298fdea947ad06400",
      "e72a899373ee4e68b2fefb08a43e7a7e",
      "e5f3306f64dc4a9b835126c5dbf6f82d",
      "92bc1285b91e4d908102b277605aea7a",
      "67569627e2d341fca4d549d72956205d",
      "42dd48429d5f490883ee1aa8eff05487",
      "39e647bfc1f34b21b7f338346b64ab46",
      "db803c126a434d279c795f5f00915568",
      "a4c39b9f632f466d8d1112b51b32f16e",
      "4af579f998f84f87b83a1f59d3609a92",
      "4abcb0d09efd411da6fcff450ca3e827",
      "e061267602f64e258d1cbe28bf3663c3",
      "6ada46d78ebe42e1a24060a4d293f20e",
      "e3d9f5806d3245fb91a9c7b8648e38fa",
      "8fb1cee7e777483f8cf482f0119ef225",
      "16876549383846669749c03b5de804f8",
      "56f2d27e071b4df0a625a05082a05d4f",
      "790da4f0d2df435d91623f113746eb25",
      "92561453948746ac9c9587627318f912",
      "6ec6be9aa1774800a3e8f9a4910a5238",
      "854634dda48a4d73a302a248da9086d8",
      "2132f5f286df4e80a8dca4a1a619fa1d",
      "c27ceea09ad746c4b0b1a3364e11c3b5",
      "4f07518c482e42fe9f4145b404c343d5",
      "1449a765197442bbac330e76da35f917",
      "557c0c8657694ce584e47f269add49d7",
      "a6b77471b1a64206b8ed19e7d273ae8d",
      "1c2f69f0e78848de976ca126778b1e0b",
      "77db040dd866446986d16bc0652a1646",
      "9bd843c6505b4b6f848d8560a969cef0",
      "71f3a00e1e8948f883fa9c3d9d83462c",
      "f474c74f1a9b49b2a0866969e454329d",
      "fdb393e75fb849b4aab609a4ab6424e0",
      "503225f6f48e476185500087fa288f81",
      "c66547a6d2c0445685101c5d775bdd3f",
      "8a02e2bdfbf840c8aeb2f36d868dbc6c",
      "3e6bcefdbf06403db203b0e145587050",
      "a625e55279904832980748f1687ac553",
      "78f31e620c974e46a2962f84605506ee",
      "c0d8fe3fc92b44289fa5662d2599e113",
      "723fcead0fd74567b39935981e40c5ec",
      "43200830630b48f4a2738a698df3402d",
      "a9d15522da614adeb4d78b8c1a13f327",
      "2846d9c0a40341e09edbbc2c71410fcc",
      "dc1d91910a73448598155687fee34f5c",
      "df97a077b6de445387715874311ebd26",
      "30ef97c04d07412b9cdc1221c7768533",
      "760377b075e8405ea0caf6aa7f283dfd",
      "cc12879c879d41c398ee30c56d78d71c",
      "ca3528414f624525bb42407c95f1c57b",
      "599a75b0c85945239ea3c5907115aedc",
      "8317102553ee4df4855e80f76b3ac279",
      "6d1b2cd0e0c348858d0cdd4b0b785e93",
      "ed36b0a236cb4f2ba454217afd2ed583",
      "4bad17901e124ddc9971e312ca98fbff",
      "bfaa725b1ae94c7b802c03dd0cbd702e",
      "c2f235b23ca04470bd79a2f52913a584",
      "611a3cdccc6c422ba9a115cbf62be3d6",
      "b813789282f940e1ade51b48d2aac405",
      "cebb11ea34664a4fbb8f6cbd70a72a61",
      "83b52c24c05f45499a3c52296d18ec5c",
      "2e7afcad6240444ea16141d8ee7cf560",
      "f377fa5d82e4485e8af9e1413b221d49",
      "8aefc17b24a54b5ba484d92a8e5713e6",
      "246a28c78d09463ea94f8b0286fc078e",
      "e4580c9d456348e3ab1de95efa8afc61",
      "b68757568e7e4cf1b9ed82d1ae89f3f1",
      "4bcbecc9aeef4acfba71523671f390d1",
      "1bbbc61ad69841ba88a8637bc0c90b68",
      "4db45224db8247ff9dd791174774f46c",
      "f88c48e63cf94db2a16c2deaf24e5c4a",
      "647e6e199ebc4559830f9fda9548c654",
      "c8548f181f6543cfa81d3f4638166ddb",
      "b96a01178fa74cd09d561f25d3e319f5",
      "2dd0ed192bf7427f99b5745bd1b5a5eb",
      "c69e25d346344a1b927f4ef833337bfc",
      "78eb3a4a1e85414ba2635e7d256f80df",
      "48ded755789e4752ac6f93326d8e1e95",
      "c22527338f38402f95d39f6cda4c75dc",
      "f7537e92ce674f1ba4259b05f506f2ac",
      "657ca0627435467da8cd4258e9eeecff",
      "db126753b48441d9b1758795fe70fcd9",
      "9bb2e33350f64a5f9698aa1c82a11355",
      "f09219cb79c6480ca308bfb768fe6da8",
      "98fca2131613486d92b358b8008fafc6",
      "63ae4fee57844de3b484a3ecb70ea11c",
      "3082ca383c494a04ab10927c880203cd",
      "9c9bb47c52df4e8e98b5675d760bf812",
      "58b8c1260d744300a91cefc99cad4ceb",
      "b7534ad4d3d643259d9f3e937c45fcc0",
      "fd6944ae21e64e98b28c96f67a00b533",
      "a6a328e044a04f6baa7d562eb9ee4ef8",
      "0261dec47e7c442ea7e2b31235ffe71f",
      "b506b915e0fb4ffcb7cf5614f8265f49"
     ]
    },
    "id": "6t-gka8n0iIG",
    "outputId": "0964944a-ba62-4d2f-8ad2-1e2c8b97fb48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Text Encoder (Mistral)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4cbb2b4e154cf8839e43f54db6ccbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07052df2bfa42e99838c7cef6e98945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/57.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5845d10c18df4f12b5f2b86006a8aade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e647bfc1f34b21b7f338346b64ab46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00001-of-00010.safete(…):   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790da4f0d2df435d91623f113746eb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00002-of-00010.safete(…):   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77db040dd866446986d16bc0652a1646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00007-of-00010.safete(…):   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d8fe3fc92b44289fa5662d2599e113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00005-of-00010.safete(…):   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599a75b0c85945239ea3c5907115aedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00006-of-00010.safete(…):   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7afcad6240444ea16141d8ee7cf560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00003-of-00010.safete(…):   0%|          | 0.00/4.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8548f181f6543cfa81d3f4638166ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00008-of-00010.safete(…):   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09219cb79c6480ca308bfb768fe6da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model-00004-of-00010.safete(…):   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_id = \"AlekseyCalvin/FLUX2_dev_2bit_hqq\"\n",
    "\n",
    "print(\"Loading Text Encoder (Mistral)...\")\n",
    "# Initialize skeleton\n",
    "text_encoder = AutoModel.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.2-dev\", # Load config from base model\n",
    "    subfolder=\"text_encoder\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGuNuLqd0iFI"
   },
   "outputs": [],
   "source": [
    "# Swap layers\n",
    "replace_with_hqq(text_encoder, hqq_config)\n",
    "# Load quantized weights\n",
    "te_path = hf_hub_download(model_id, filename=\"text_encoder/model.safetensors\")\n",
    "te_state_dict = load_file(te_path)\n",
    "text_encoder.load_state_dict(te_state_dict)\n",
    "text_encoder = text_encoder.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikYtEFmu1A7o"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Loading Transformer (Flux 2)...\")\n",
    "# Initialize skeleton\n",
    "transformer = Flux2Transformer2DModel.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.2-dev\",\n",
    "    subfolder=\"transformer\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Al0bYSW91A5K"
   },
   "outputs": [],
   "source": [
    "# Swap layers\n",
    "replace_with_hqq(transformer, hqq_config)\n",
    "# Load quantized weights\n",
    "tr_path = hf_hub_download(model_id, filename=\"transformer/diffusion_pytorch_model.safetensors\")\n",
    "tr_state_dict = load_file(tr_path)\n",
    "transformer.load_state_dict(tr_state_dict)\n",
    "transformer = transformer.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Koa39LUf1A2w"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Assembling Pipeline...\")\n",
    "pipe = Flux2Pipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.2-dev\",\n",
    "    transformer=transformer,\n",
    "    text_encoder=text_encoder,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "pipe.enable_model_cpu_offload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqrYnJ_u1A0V"
   },
   "outputs": [],
   "source": [
    "rint(\"Ready for Inference!\")\n",
    "prompt = \"A photo of a sneaky koala hiding behind book stacks at a library, calm snowy landscape visible through large window in the backdrop...\"\n",
    "image = pipe(prompt, guidance_scale=4, num_inference_steps=40).images[0]\n",
    "image.save(\"KoalaTesting.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbNaUcQR0iCO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "9773e0f4a6024ed491ed5f79714acbac",
      "9e9b79244867436aab0d61066672a76e",
      "43e7bde0f8f94ebc9ea86580eb642af3",
      "79629c72b2c04aa8be75398cb990e3f2",
      "7980ca2e80d34bc2a375487e2d17e6f6",
      "bc62748625564f798459d9fe25098e14",
      "5e12c8f277754190b8bd87843e131a61",
      "91903b0506174183bef5d0026d747f70",
      "f11a0baf6f5c45f3841d483ee7605c79",
      "7c518ea815574f279d014b6b580141c6",
      "8ae753a30ee34bf393807662f2656691"
     ]
    },
    "id": "zmrkjclL2c8B",
    "outputId": "8948b582-4019-4323-89eb-44b9322f1f57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9773e0f4a6024ed491ed5f79714acbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flux2-dev-Q3_K_S.gguf:   0%|          | 0.00/15.8G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/root/.cache/huggingface/hub/models--city96--FLUX.2-dev-gguf/snapshots/ade5d688ddab0d9cf4a5b01bf4321e01c115020d/flux2-dev-Q3_K_S.gguf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_id = \"city96/FLUX.2-dev-gguf\"\n",
    "\n",
    "hf_hub_download(repo_id=model_id, filename=\"flux2-dev-Q3_K_S.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcEeZIpEyGaq"
   },
   "outputs": [],
   "source": [
    "flux_gguf_file_path = \"/root/.cache/huggingface/hub/models--city96--FLUX.2-dev-gguf/snapshots/ade5d688ddab0d9cf4a5b01bf4321e01c115020d/flux2-dev-Q3_K_S.gguf\" # Copy paste the actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DI8TmKnfwN9e",
    "outputId": "db144eb8-05fd-4f6c-9129-39970b54a3d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
      "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import Flux2Pipeline, BitsAndBytesConfig\n",
    "from diffusers.utils import load_image\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGCIzUwgwu8Y"
   },
   "outputs": [],
   "source": [
    "repo_id = \"diffusers/FLUX.2-dev-bnb-4bit\" #quantized text-encoder and DiT. VAE still in bf16\n",
    "device = \"cuda\"\n",
    "torch_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dn_GoDTq0AxL"
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from diffusers.quantizers import PipelineQuantizationConfig\n",
    "\n",
    "pipeline_quant_config = PipelineQuantizationConfig(\n",
    "    quant_backend=\"bitsandbytes_4bit\",\n",
    "    quant_kwargs={\"load_in_4bit\": True, \"bnb_4bit_quant_type\": \"nf4\", \"bnb_4bit_compute_dtype\": torch.bfloat16},\n",
    "    components_to_quantize=[\"transformer\", \"text_encoder_2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxgi4oKLxc8p"
   },
   "outputs": [],
   "source": [
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    repo_id,\n",
    "    quantization_config=pipeline_quant_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOQrvZU3xhEw"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"A focused software engineer sitting at a modern desk, writing Python code on a dual-monitor setup. The screens display clean, well-formatted Python scripts with functions, classes, and comments. Soft ambient lighting, a minimalistic workspace, laptop, mechanical keyboard, and a cup of coffee nearby. The engineer is deeply concentrated, with subtle reflections of code on their glasses. Futuristic tech vibe, high-resolution, ultra-realistic lighting, professional workspace atmosphere.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhVKbzhX2DDS"
   },
   "outputs": [],
   "source": [
    "image = pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLTmnjxjyBmB"
   },
   "outputs": [],
   "source": [
    "image"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mzhCbLWuYMDz",
    "k2zz4bZTTlGH",
    "lSHHty19wKO6"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
