{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWO78cbWevQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9069adf0-8ffb-4256-dcdb-4cc2899248c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.24.0-py3-none-any.whl (37 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1->replicate) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>1->replicate) (2.16.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 replicate-0.24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['REPLICATE_API_TOKEN'] = ''"
      ],
      "metadata": {
        "id": "ggT9yIwpzU2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate"
      ],
      "metadata": {
        "id": "dQZInKqj2klN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = replicate.run(\n",
        "    \"google-deepmind/gemma-7b-it:2790a695e5dcae15506138cc4718d1106d0d475e6dca4b1d43f42414647993d5\",\n",
        "    input={\n",
        "        \"top_k\": 50,\n",
        "        \"top_p\": 0.95,\n",
        "        \"prompt\": \"Write me a poem about Machine Learning.\",\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_new_tokens\": 512,\n",
        "        \"min_new_tokens\": -1,\n",
        "        \"repetition_penalty\": 1\n",
        "    }\n",
        ")\n",
        "\n",
        "# The google-deepmind/gemma-7b-it model can stream output as it's running.\n",
        "# The predict method returns an iterator, and you can iterate over that output.\n",
        "for item in output:\n",
        "    # https://replicate.com/google-deepmind/gemma-7b-it/api#output-schema\n",
        "    print(item, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_qoRqIG27Ki",
        "outputId": "cf3ec2f9-d4a9-458f-9f40-6d33e08d0c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "In the realm of data, where insights bloom,\n",
            "A tale unfolds, of algorithms' doom.\n",
            "No longer shall humans toil in vain,\n",
            "But empower machines to learn, and gain.\n",
            "\n",
            "With neural networks, a labyrinth of code,\n",
            "They decipher patterns, stories untold.\n",
            "From images to text, they glean,\n",
            "The secrets hidden within the digital scene.\n",
            "\n",
            "With each iteration, they evolve,\n",
            "Uncovering insights, hidden in the groove.\n",
            "A symphony of learning, a dance of grace,\n",
            "Machine learning, a transformative force, in place.\n",
            "\n",
            "But with great power, comes great responsibility,\n",
            "To safeguard fairness, and mitigate bias.\n",
            "In the hands of humans, it's a tool,\n",
            "A catalyst for progress, a guiding rule.\n",
            "\n",
            "So let us harness the power of this might,\n",
            "To uplift society, cast away the night.\n",
            "With machine learning, let's unlock new heights,\n",
            "And build a future filled with boundless lights."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = replicate.run(\n",
        "    \"lucataco/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\",\n",
        "    input={\n",
        "        \"seed\": 2992471961,\n",
        "        \"width\": 1024,\n",
        "        \"height\": 1024,\n",
        "        \"prompt\": \"farmer cutting wifes hair\",\n",
        "        \"scheduler\": \"K_EULER\",\n",
        "        \"num_outputs\": 1,\n",
        "        \"guidance_scale\": 0,\n",
        "        \"negative_prompt\": \"worst quality, low quality\",\n",
        "        \"num_inference_steps\": 4\n",
        "    }\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLH3ROD-Cyr",
        "outputId": "75943939-b379-403d-947b-fabb6dd35a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://replicate.delivery/pbxt/e03If3YH37uCJ0U5ZAUjhZMs62sMLG2Xu0eN9hdQMTaLqO3kA/out-0.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from llma.preprocessing import NormalizeMeanZeroStd\n",
        "from llma.utils import to_categorical\n",
        "from llma.evaluation import Evaluator\n",
        "\n",
        "# Load Boston Housing dataset\n",
        "boston = fetch_boston()\n",
        "X = boston.data[:, :2]  # we only take the first two features.\n",
        "y = boston.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Preprocess the data\n",
        "normalizer = NormalizeMeanZeroStd()\n",
        "X_train = normalizer.fit_transform(train_X)\n",
        "val_X = normalizer.transform(val_X)\n",
        "\n",
        "# Convert categorical variables to numerical values\n",
        "to_categorical = to_categorical\n",
        "onehot_encodings = {0: '0', 1: '1'}\n",
        "X_train['cat'] = X_train['cat'].apply(lambda x: to_categorical(x, onehot_encodings))\n",
        "val_X['cat'] = val_X['cat'].apply(lambda x: to_categorical(x, onehot_encodings))\n",
        "\n",
        "# Create and compile the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(2,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, train_y, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "eval = Evaluator()"
      ],
      "metadata": {
        "id": "TV5_upqZZvyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch accelerate"
      ],
      "metadata": {
        "id": "qVR-o826DbgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAdlPWtuj1g5",
        "outputId": "9a15096e-0efc-4d2f-abb7-1122be4a4535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli whoami"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noFIN3n_lpGP",
        "outputId": "a979fdef-beab-43b4-d6cf-9299b8707f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "krrishv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxjmkFbJltuA",
        "outputId": "9d251c26-5b68-4a50-f389-2af22d35fb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_name  = 'meta-llama/Llama-2-7b-hf'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "sXlL1Wkwly9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}