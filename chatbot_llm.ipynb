{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zR_g82sVNGl",
        "outputId": "087c73a9-925e-4a0b-a6b1-735cd9e8e35f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.43)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.20.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.1.48)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.0.7)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "!pip install -qqq openai\n",
        "!pip install -Uqqq chromadb\n",
        "!pip install -q tiktoken\n",
        "!pip install -q langchain\n",
        "!pip install -q pypdf\n",
        "!pip install -q accelerate\n",
        "!pip install -U langchain-openai\n",
        "!pip install -q PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkJz6dR3VYnC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import langchain\n",
        "import chromadb\n",
        "import torch\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BeafGZCVaSw"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(file_id, destination):\n",
        "\n",
        "    url = \"https://drive.google.com/uc?id=\" + file_id\n",
        "    response = requests.get(url, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        with open(destination, 'wb') as f:\n",
        "            for chunk in response.iter_content(1024 * 1024):\n",
        "                f.write(chunk)\n",
        "\n",
        "        print(\"File downloaded successfully\")\n",
        "    else:\n",
        "        print(\"Failed to download file\")\n",
        "\n",
        "file_id_list = ['1VIKVkxBXKwpfAieBrZ_OSTMfzhBjVoCb', '18yLsAli-G8erNjutq5YnJRUQlbH3LoMv', '1HfPb48GercUt2sm9Jcug1RzX1HmKNa9m'] # all there file given in email\n",
        "destination_list = ['file1.pdf', 'file2.pdf', 'file3.pdf']\n",
        "\n",
        "for file_id, destination in zip(file_id_list, destination_list):\n",
        "    download_file_from_google_drive(file_id, destination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAc7W5PSk0wO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFh89Dnif1Dq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_chunk_persist_pdf() -> Chroma:\n",
        "    pdf_folder_path = \"/content\"\n",
        "    documents = []\n",
        "    for file in os.listdir(pdf_folder_path):\n",
        "        if file.endswith('.pdf'):\n",
        "            pdf_path = os.path.join(pdf_folder_path, file)\n",
        "\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            documents.extend(loader.load())\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(separator = \"\\n\", chunk_size=1000, chunk_overlap=10)\n",
        "    chunked_documents = text_splitter.split_documents(documents)\n",
        "    '''\n",
        "    client = chromadb.Client()\n",
        "    if client.list_collections(): OpenAIEmbeddings.create_collection(\"consent_collection\")\n",
        "    else:\n",
        "        print(\"Collection already exists\")\n",
        "    '''\n",
        "    vectordb = Chroma.from_documents(chunked_documents, OpenAIEmbeddings())\n",
        "    return vectordb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yEMpG05hgg_"
      },
      "outputs": [],
      "source": [
        "db = load_chunk_persist_pdf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De7HO3mktMmx"
      },
      "outputs": [],
      "source": [
        "db.similarity_search('', k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTJ1jqTaVdBC",
        "outputId": "ceacb829-766f-40fc-d450-e5188a859be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjpoWLAIVds-"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "pipeline = transformers.pipeline(\n",
        "      \"text-generation\", #task\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "      torch_dtype=torch.bfloat16,\n",
        "      trust_remote_code=True,\n",
        "      device_map=\"auto\",\n",
        "      max_length=1000,\n",
        "      do_sample=True,\n",
        "      top_k=10,\n",
        "      num_return_sequences=1,\n",
        "      eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq84L3f0Vsq2"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are a intelligent assiatance where you have to guide the user on the bases of the question that are been aksed, you do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'.\n",
        "\n",
        "\n",
        "Question - {question}\n",
        "\n",
        "This is the context on which the bellow question is based - {context}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0KUn-SXWNCm"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW67C092WPG-",
        "outputId": "8589a280-01fa-4a85-ab06-4d9666222849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a intelligent assiatance where you have to guide the user on the bases of the question that are been aksed, you do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'.\n",
            "\n",
            "Question - this is my question?\n",
            "\n",
            "This is the context on which the bellow question is based - context\n",
            "\n",
            "Answer:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    prompt.format(\n",
        "        question = \"this is my question?\",\n",
        "        context = 'context'\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHPQhU1zWQ52"
      },
      "outputs": [],
      "source": [
        "\n",
        "chain_type_kwargs = {\"prompt\": prompt}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtAeGWiSXJaU"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9vmeC6FWS0y"
      },
      "outputs": [],
      "source": [
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1}),\n",
        "    chain_type_kwargs=chain_type_kwargs,\n",
        "    memory = memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iie2RqBWUs3"
      },
      "outputs": [],
      "source": [
        "def chain_response(question):\n",
        "  resp =  chain.invoke(question)\n",
        "  return resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRcpVgaIcFa7"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What are the advantages and disadvantages of Limited Liability Corporation?\",\n",
        "    \"What are the demand and supply schedules for sweatshirts?\",\n",
        "    \"Differentiate between Chirs's LandScaping and Clear Lake Sporting Goods and tell which is better?\",\n",
        "    \"Tell me about Reliance Industries Limited and what are the equity shares of Reliance Industries Limited?\",\n",
        "    \"Define the profit and loss for the year ended 31st March,2013 of Mr. Sexena trading book?\",\n",
        "    \"Difference between Branch Accounts and Departmental Accounts ?\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PrJrp5AWcQw"
      },
      "outputs": [],
      "source": [
        "def show_response(output):\n",
        "    return output['result'].split('Answer:')[1].replace('\\n', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7fHzvuNWWsK"
      },
      "outputs": [],
      "source": [
        "for q in questions:\n",
        "    respn = show_response(chain_response(q))\n",
        "    print(respn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  quest = str(input(\"User: \"))\n",
        "  print('Answer: ', show_response(chain_response(quest)))"
      ],
      "metadata": {
        "id": "npv7zAsqwd3Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}